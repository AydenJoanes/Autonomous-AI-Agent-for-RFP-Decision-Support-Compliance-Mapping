## **RISK 3: RequirementType Enum Ambiguity ✅ VALID \- CLARIFIED**

**Solution:** Clear definitions in model docstrings

**Distinctions:**

* MANDATORY \= Eligibility/compliance (ISO 27001, HIPAA, location)  
* TECHNICAL \= Skills/technologies (Python, AWS, React)  
* TIMELINE \= Delivery timeframe  
* BUDGET \= Financial constraints  
* PREFERRED \= Nice-to-have  
* OTHER \= Catch-all (with strict validation to prevent junk)

---

## **PHASE 3: UPDATED IMPLEMENTATION PLAN**

---

### **STEP 1: Define Requirement Model**

**Create `app/models/requirement.py`:**

**Import statements:**

* \[ \] Import Pydantic BaseModel, Field, validator  
* \[ \] Import Enum from enum  
* \[ \] Import Optional, List from typing  
* \[ \] Import UUID from uuid

**Define RequirementType enum:**

* \[ \] Create enum with values: MANDATORY, TECHNICAL, PREFERRED, TIMELINE, BUDGET, OTHER  
* \[ \] Add docstring explaining each type:  
  * MANDATORY: Eligibility requirements (certifications, compliance, legal)  
  * TECHNICAL: Technology and skill requirements (languages, frameworks, platforms)  
  * PREFERRED: Nice-to-have features (bonus, not required)  
  * TIMELINE: Delivery schedule and milestones  
  * BUDGET: Financial constraints and limits  
  * OTHER: Items that don't fit above (use sparingly)

**Define Requirement model:**

* \[ \] Field: id (Optional UUID, auto-generated)  
* \[ \] Field: text (str, required, requirement description)  
* \[ \] Field: type (RequirementType, required)  
* \[ \] Field: category (str, required, subcategory like "certification", "cloud")  
* \[ \] Field: priority (int, required, 1-10 scale)  
* \[ \] Field: source\_section (Optional str, where found in RFP)  
* \[ \] Field: embedding (Optional List\[float\], 1536 dimensions for OpenAI)  
* \[ \] Field: confidence (Optional float, 0-1, LLM classification confidence)  
* \[ \] Field: metadata (Optional dict, additional context)

**Add validators:**

* \[ \] Validator: text must not be empty  
* \[ \] Validator: priority must be 1-10  
* \[ \] Validator: embedding length must be 1536 if present  
* \[ \] Validator: confidence must be 0-1 if present  
* \[ \] Validator: if type is OTHER, require metadata explaining why

---

### **STEP 2: Create Base Parser**

**Create `app/parsers/base_parser.py`:**

**Define abstract base class:**

* \[ \] Import ABC, abstractmethod  
* \[ \] Define BaseParser class  
* \[ \] Abstract method: parse(file\_path: str) returns str (markdown)  
* \[ \] Abstract method: supports\_format(file\_path: str) returns bool  
* \[ \] Concrete method: validate\_file(file\_path: str)  
  * Check file exists  
  * Check file readable  
  * Check file size (\< 10MB)  
  * Raise exception if invalid

---

### **STEP 3: Implement Docling Parser**

**Create `app/parsers/docling_parser.py`:**

**Implement DoclingParser:**

* \[ \] Extend BaseParser  
* \[ \] Import Docling library  
* \[ \] Import logger from loguru

**Method: supports\_format():**

* \[ \] Check file extension in \['.pdf', '.docx', '.doc'\]  
* \[ \] Return True if supported

**Method: parse():**

* \[ \] Log: "Starting Docling parse for {filename}"  
* \[ \] Validate file using base method  
* \[ \] Initialize Docling converter  
* \[ \] Convert document to markdown  
* \[ \] Preserve table structures  
* \[ \] Clean excessive whitespace  
* \[ \] Count words in output  
* \[ \] Log: "Docling parse complete: {word\_count} words"  
* \[ \] Return markdown string

**Error handling:**

* \[ \] Try-catch around Docling operations  
* \[ \] Log full error with traceback  
* \[ \] Re-raise with context (filename, error type)

---

### **STEP 4: Implement Fallback Parsers**

**Create `app/parsers/pypdf_parser.py`:**

* \[ \] Extend BaseParser  
* \[ \] Import pypdf library  
* \[ \] Implement supports\_format() for .pdf only  
* \[ \] Implement parse():  
  * Extract text from all pages  
  * Join pages with newlines  
  * Basic markdown formatting  
  * Return as string  
* \[ \] Log: "Using PyPDF fallback parser"

**Create `app/parsers/docx_parser.py`:**

* \[ \] Extend BaseParser  
* \[ \] Import python-docx library  
* \[ \] Implement supports\_format() for .docx, .doc  
* \[ \] Implement parse():  
  * Extract all paragraphs  
  * Extract tables (convert to markdown tables)  
  * Combine into markdown  
  * Return as string  
* \[ \] Log: "Using python-docx fallback parser"

---

### **STEP 5: Create Parser Factory**

**Create `app/parsers/document_parser_factory.py`:**

**Import all parsers:**

* \[ \] Import DoclingParser, PyPDFParser, DocxParser  
* \[ \] Import logger

**Define DocumentParserFactory class:**

**Method: get\_file\_extension():**

* \[ \] Extract extension from file path  
* \[ \] Convert to lowercase  
* \[ \] Return extension

**Method: create\_parser():**

* \[ \] Get file extension  
* \[ \] Log: "Selecting parser for {extension}"  
* \[ \] Return DoclingParser instance (primary)

**Method: parse\_with\_fallback():**

* \[ \] Get file extension  
* \[ \] Log: "Attempting parse with fallback chain"  
* \[ \] Try primary: DoclingParser.parse()  
  * If success: Log success, return markdown  
* \[ \] Catch exception from primary:  
  * Log: "Docling failed: {error}"  
  * If PDF: Try PyPDFParser.parse()  
  * If DOCX: Try DocxParser.parse()  
  * If success: Log fallback success, return markdown  
* \[ \] If all fail:  
  * Log: "All parsers failed for {filename}"  
  * Raise exception with all error messages  
* \[ \] Return markdown string

---

### **STEP 6: Create Embedding Utility (OpenAI)**

**Create or update `app/utils/embeddings.py`:**

**Configuration:**

* \[ \] Import OpenAI client  
* \[ \] Import settings  
* \[ \] Define constant: EMBEDDING\_MODEL \= "text-embedding-3-small"  
* \[ \] Define constant: EMBEDDING\_DIMENSION \= 1536

**Initialize OpenAI client:**

* \[ \] Create client with API key from settings  
* \[ \] Log: "Embedding utility initialized with {model}"

**Function: generate\_embedding():**

* \[ \] Parameter: text (str)  
* \[ \] Returns: List\[float\]  
* \[ \] Validate text not empty  
* \[ \] Call OpenAI embeddings API  
* \[ \] Extract embedding vector from response  
* \[ \] Validate dimension \= 1536  
* \[ \] Log: "Generated embedding for {text\_length} chars"  
* \[ \] Return embedding list

**Error handling:**

* \[ \] Try-catch for API errors  
* \[ \] Retry on timeout (3 attempts with exponential backoff)  
* \[ \] Log all errors with context  
* \[ \] Raise exception if all retries fail

**Function: generate\_batch\_embeddings():**

* \[ \] Parameter: texts (List\[str\])  
* \[ \] Returns: List\[List\[float\]\]  
* \[ \] Batch API call (max 100 texts per call)  
* \[ \] Handle batching if \> 100 texts  
* \[ \] Return list of embeddings in same order

---

### **STEP 7: Create RFP Parser Tool**

**Create `app/agent/tools/rfp_parser_tool.py`:**

**Import dependencies:**

* \[ \] Import DocumentParserFactory  
* \[ \] Import logger  
* \[ \] Import BaseTool from LangChain (if using)

**Define RFPParserTool class:**

* \[ \] Tool name: "rfp\_parser"  
* \[ \] Tool description: "Parses RFP documents (PDF/DOCX) and converts to clean markdown text. Handles complex layouts and tables."

**Method: \_run():**

* \[ \] Parameter: file\_path (str)  
* \[ \] Log: "\[TOOL\] RFP Parser started for {filename}"  
* \[ \] Validate file\_path exists  
* \[ \] Call DocumentParserFactory.parse\_with\_fallback(file\_path)  
* \[ \] Count words in markdown  
* \[ \] Log: "\[TOOL\] RFP Parser complete: {word\_count} words"  
* \[ \] Return markdown text

**Error handling:**

* \[ \] Catch parsing errors  
* \[ \] Log error with full context  
* \[ \] Return error message (don't crash agent)

---

### **STEP 8: Create Requirement Processor Tool (Merged)**

**Create `app/agent/tools/requirement_processor_tool.py`:**

**Import dependencies:**

* \[ \] Import Langextract library  
* \[ \] Import OpenAI client  
* \[ \] Import generate\_embedding from utils  
* \[ \] Import Requirement model  
* \[ \] Import logger  
* \[ \] Import json, re

**Define RequirementProcessorTool class:**

* \[ \] Tool name: "requirement\_processor"  
* \[ \] Tool description: "Extracts, classifies, and generates embeddings for all requirements from RFP markdown text"

**Method: \_run():**

* \[ \] Parameter: rfp\_markdown (str)  
* \[ \] Returns: List\[Requirement\]  
* \[ \] Log: "\[TOOL\] Requirement Processor started"

**Step 1: Extract raw requirements (Langextract):**

* \[ \] Log: "\[EXTRACT\] Starting requirement extraction"  
* \[ \] Try-catch block:  
  * \[ \] Use Langextract to find requirement patterns  
  * \[ \] Extract certifications, technologies, budget mentions, timeline mentions  
  * \[ \] Extract deliverables and constraints  
  * \[ \] Store as list of raw requirement strings  
  * \[ \] Log: "\[EXTRACT\] Found {count} raw requirements"  
* \[ \] On error:  
  * \[ \] Log: "\[EXTRACT\] Failed: {error}"  
  * \[ \] Return empty list (graceful degradation)

**Step 2: Classify requirements (LLM):**

* \[ \] Log: "\[CLASSIFY\] Starting LLM classification"  
* \[ \] Build classification prompt:  
  * Include raw requirements  
  * Ask LLM to classify each as MANDATORY/TECHNICAL/PREFERRED/TIMELINE/BUDGET/OTHER  
  * Ask for priority 1-10  
  * Ask for category (certification/technology/timeline/budget/deliverable)  
  * Ask for confidence 0-1  
  * Request JSON output format  
* \[ \] Try-catch with retry (3 attempts):  
  * \[ \] Call OpenAI GPT-4o-mini  
  * \[ \] Parse JSON response  
  * \[ \] Validate structure  
  * \[ \] Log: "\[CLASSIFY\] Classified {count} requirements"  
* \[ \] On error:  
  * \[ \] Log: "\[CLASSIFY\] Failed: {error}"  
  * \[ \] Retry with exponential backoff  
  * \[ \] If all retries fail: Return partial results (requirements without classification)

**Step 3: Generate embeddings (OpenAI):**

* \[ \] Log: "\[EMBED\] Starting embedding generation"  
* \[ \] Try-catch block:  
  * \[ \] Extract all requirement texts  
  * \[ \] Call generate\_batch\_embeddings() for efficiency  
  * \[ \] Attach embeddings to requirements  
  * \[ \] Validate all embeddings dimension \= 1536  
  * \[ \] Log: "\[EMBED\] Generated {count} embeddings"  
* \[ \] On error:  
  * \[ \] Log: "\[EMBED\] Failed: {error}"  
  * \[ \] Continue (requirements still valid without embeddings)  
  * \[ \] Set embedding \= None for failed items

**Step 4: Validate and build Requirement objects:**

* \[ \] Log: "\[VALIDATE\] Validating requirement objects"  
* \[ \] For each classified requirement:  
  * \[ \] Create Requirement object with all fields  
  * \[ \] Validate using Pydantic  
  * \[ \] Add success flag indicating completed steps  
* \[ \] Filter out invalid requirements  
* \[ \] Log: "\[VALIDATE\] {count} valid requirements"

**Step 5: Return results:**

* \[ \] Log: "\[TOOL\] Requirement Processor complete: {count} requirements"  
* \[ \] Return list of Requirement objects

**Error handling strategy:**

* \[ \] Each step independent with try-catch  
* \[ \] Partial results acceptable  
* \[ \] Log all errors with step marker  
* \[ \] Never crash \- return what we have

---

### **STEP 9: Update Database Schema**

**Modify `app/database/schema.py`:**

**Update RFPUpload table:**

* \[ \] Add column: parsed\_markdown (Text, nullable)  
* \[ \] Add column: parsed\_at (DateTime, nullable)  
* \[ \] Add column: parser\_used (String, nullable \- "docling", "pypdf", "docx")

**Recreate database:**

* \[ \] Run: python scripts/setup\_database.py  
* \[ \] Verify new columns exist

---

### **STEP 10: Create Test Script**

**Create `scripts/test_requirement_extraction.py`:**

**Import dependencies:**

* \[ \] Import DocumentParserFactory  
* \[ \] Import RequirementProcessorTool  
* \[ \] Import pathlib, json, os  
* \[ \] Import logger

**Setup:**

* \[ \] Define sample\_rfps\_dir \= "data/sample\_rfps/"  
* \[ \] Define output\_dir \= "data/test\_output/"  
* \[ \] Create output directory if not exists

**Main test function:**

* \[ \] Find all PDF/DOCX files in sample\_rfps\_dir  
* \[ \] For each file:  
  * \[ \] Log: "Testing {filename}"  
  * \[ \] Parse document to markdown  
  * \[ \] Save markdown to output\_dir/{filename}\_parsed.md  
  * \[ \] Process requirements  
  * \[ \] Save requirements to output\_dir/{filename}\_requirements.json  
  * \[ \] Print summary:  
    * Filename  
    * Word count  
    * Requirements count  
    * Type distribution (X mandatory, Y technical, etc.)  
    * Embeddings status (X with embeddings, Y without)  
  * \[ \] Flag issues (no requirements found, missing embeddings, all type=OTHER)

**Summary statistics:**

* \[ \] Total RFPs processed  
* \[ \] Total requirements extracted  
* \[ \] Average requirements per RFP  
* \[ \] Embedding coverage percentage  
* \[ \] Parsing success rate

**Run:**

* \[ \] Add if **name** \== "**main**" block  
* \[ \] Execute test function  
* \[ \] Print final summary

---

### **STEP 11: Documentation**

**Create or update `docs/PHASE3.md`:**

**Document embedding strategy:**

* \[ \] Model: OpenAI text-embedding-3-small  
* \[ \] Dimension: 1536  
* \[ \] Used for: ALL embeddings (requirements AND knowledge base)  
* \[ \] Rationale: Consistency across system

**Document RequirementType definitions:**

* \[ \] Copy enum docstrings  
* \[ \] Provide 3 examples for each type  
* \[ \] Explain ambiguous cases (TECHNICAL vs MANDATORY)

**Document tool workflow:**

* \[ \] RFP Parser Tool → Markdown  
* \[ \] Requirement Processor Tool → Structured requirements  
* \[ \] Each tool's responsibilities  
* \[ \] Error handling strategy

**Document fallback chain:**

* \[ \] Primary: Docling (best quality)  
* \[ \] Fallback PDF: PyPDF  
* \[ \] Fallback DOCX: python-docx  
* \[ \] When each is used

---

## **VERIFICATION CHECKLIST**

### **✅ Code Structure:**

* \[ \] All parser files created in app/parsers/  
* \[ \] All tool files created in app/agent/tools/  
* \[ \] Models defined in app/models/requirement.py  
* \[ \] Embedding utility in app/utils/embeddings.py  
* \[ \] Test script in scripts/  
* \[ \] No import errors when running Python

### **✅ Parsing:**

* \[ \] Sample RFPs parse successfully to markdown  
* \[ \] Markdown output is clean and readable  
* \[ \] Tables preserved in markdown format  
* \[ \] Fallback parsers activate when Docling fails  
* \[ \] Logs show which parser was used

### **✅ Requirement Extraction:**

* \[ \] Each sample RFP produces 6-15 requirements  
* \[ \] Requirements have all required fields  
* \[ \] Type distribution makes sense (not all OTHER)  
* \[ \] Priorities correlate with types (MANDATORY \= 9-10)  
* \[ \] Categories are logical and specific

### **✅ Classification:**

* \[ \] MANDATORY vs TECHNICAL distinction clear  
* \[ \] No inappropriate use of OTHER type  
* \[ \] Confidence scores present (0-1 range)  
* \[ \] LLM classification consistent across runs

### **✅ Embeddings:**

* \[ \] All requirements have embeddings (or flag missing)  
* \[ \] All embeddings dimension \= 1536 (OpenAI)  
* \[ \] Embeddings are non-zero vectors  
* \[ \] Similar requirements have similar embeddings (cosine \> 0.7)  
* \[ \] Batch generation works for efficiency

### **✅ Error Handling:**

* \[ \] Corrupt file doesn't crash \- uses fallback  
* \[ \] Missing file raises clear error message  
* \[ \] LLM timeout retries 3 times with backoff  
* \[ \] Partial results returned on embedding failure  
* \[ \] All errors logged with step markers

### **✅ Logging:**

* \[ \] Each step has clear log marker (\[EXTRACT\], \[CLASSIFY\], etc.)  
* \[ \] Errors logged with full context  
* \[ \] Success metrics logged (count, time)  
* \[ \] Logs written to logs/agent.log

### **✅ Test Script:**

* \[ \] Runs without errors for all sample RFPs  
* \[ \] Generates markdown files in test\_output/  
* \[ \] Generates requirement JSON files in test\_output/  
* \[ \] Summary table displays correctly  
* \[ \] Flags issues automatically

### **✅ Consistency:**

* \[ \] Embedding model consistent with Phase 2 (OpenAI, 1536-dim)  
* \[ \] No dimension mismatches  
* \[ \] All components use embeddings.py utility  
* \[ \] Documentation updated with embedding strategy

---

## **PHASE 3 COMPLETE WHEN:**

✅ All sample RFPs parse to markdown  
 ✅ Requirements extracted with 85%+ quality  
 ✅ All embeddings 1536-dim (OpenAI)  
 ✅ Logs clearly show each step  
 ✅ Test script runs and produces output  
 ✅ No critical errors or crashes  
 ✅ Ready for Phase 4 (Reasoning Engine)

---

**Updated plan addresses all feedback and uses OpenAI embeddings consistently.**